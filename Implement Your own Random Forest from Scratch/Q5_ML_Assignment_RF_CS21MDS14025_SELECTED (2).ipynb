{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "be3f0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00e2eaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from operator import le, eq\n",
    "from more_itertools import numeric_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8baa3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import functools\n",
    "import time\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9488369",
   "metadata": {},
   "source": [
    "### version of python & libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c1e0dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.8 (default, Apr 13 2021, 15:08:03) [MSC v.1916 64 bit (AMD64)]\n",
      "numpy version 1.20.1\n",
      "pandas version 1.2.4\n",
      "sklearn version 0.24.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "print('numpy version',np.__version__)\n",
    "print('pandas version',pd.__version__)\n",
    "print('sklearn version',sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59cf373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Answers', 'loan_test.csv', 'loan_train.csv', 'Self Study', 'spam.data.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(r'C:\\Users\\saura\\OneDrive\\Documents\\IIT Hyderabad\\Assignments\\ML\\Assignment_3')\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2e5c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "myname = 'Sauradeep-Debnath-'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a84068",
   "metadata": {},
   "source": [
    "# LOAD datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05bbdf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{dtype('float64'), dtype('int64')}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.00   \n",
       "\n",
       "      49   50     51     52     53     54   55    56  57  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61   278   1  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101  1028   1  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485  2259   1  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40   191   1  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40   191   1  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df = pd.read_csv('spam.data.txt', delimiter = \" \", header=None)\n",
    "print(set(spam_df.dtypes.tolist()))\n",
    "spam_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a8499d",
   "metadata": {},
   "source": [
    "### checking the distribution of positive & negative classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22a17e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2788\n",
       "1    1813\n",
       "Name: 57, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df[57].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afcf7cac",
   "metadata": {},
   "source": [
    "### separating the x /features from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d6470355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61.0</td>\n",
       "      <td>278.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1028.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485.0</td>\n",
       "      <td>2259.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0     1     2    3     4     5     6     7     8     9   ...   47    48  \\\n",
       "0  0.00  0.64  0.64  0.0  0.32  0.00  0.00  0.00  0.00  0.00  ...  0.0  0.00   \n",
       "1  0.21  0.28  0.50  0.0  0.14  0.28  0.21  0.07  0.00  0.94  ...  0.0  0.00   \n",
       "2  0.06  0.00  0.71  0.0  1.23  0.19  0.19  0.12  0.64  0.25  ...  0.0  0.01   \n",
       "3  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.0  0.00   \n",
       "4  0.00  0.00  0.00  0.0  0.63  0.00  0.31  0.63  0.31  0.63  ...  0.0  0.00   \n",
       "\n",
       "      49   50     51     52     53     54     55      56  \n",
       "0  0.000  0.0  0.778  0.000  0.000  3.756   61.0   278.0  \n",
       "1  0.132  0.0  0.372  0.180  0.048  5.114  101.0  1028.0  \n",
       "2  0.143  0.0  0.276  0.184  0.010  9.821  485.0  2259.0  \n",
       "3  0.137  0.0  0.137  0.000  0.000  3.537   40.0   191.0  \n",
       "4  0.135  0.0  0.135  0.000  0.000  3.537   40.0   191.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_df_X = spam_df.iloc[:,:-1].astype(np.float32)\n",
    "spam_target_Y = spam_df.iloc[:,-1].astype(np.int16)\n",
    "spam_df_X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2a9fb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int16')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_target_Y.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fbab03",
   "metadata": {},
   "source": [
    "### Test Train Split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b39e22af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(spam_df_X, spam_target_Y, test_size=0.3, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f33e2726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3049</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.599</td>\n",
       "      <td>0.148</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.947</td>\n",
       "      <td>102.0</td>\n",
       "      <td>564.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3225</th>\n",
       "      <td>2.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.888</td>\n",
       "      <td>29.0</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>0.00</td>\n",
       "      <td>14.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.800</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4124</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.225</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0      1     2    3     4     5    6     7     8     9   ...   47  \\\n",
       "3049  0.00   0.00  0.00  0.0  0.00  0.00  0.0  0.00  0.00  0.00  ...  0.0   \n",
       "872   0.45   0.00  0.67  0.0  0.22  0.67  0.0  0.67  0.22  0.22  ...  0.0   \n",
       "3225  2.00   0.00  0.00  0.0  0.00  0.00  0.0  0.00  0.00  0.00  ...  0.0   \n",
       "3135  0.00  14.28  0.00  0.0  0.00  0.00  0.0  0.00  0.00  0.00  ...  0.0   \n",
       "4124  0.00   0.00  0.00  0.0  0.00  0.00  0.0  0.00  0.00  0.00  ...  0.0   \n",
       "\n",
       "       48     49   50     51     52   53     54     55     56  \n",
       "3049  0.0  0.000  0.0  0.000  0.000  0.0  1.000    1.0    6.0  \n",
       "872   0.0  0.111  0.0  1.599  0.148  0.0  4.947  102.0  564.0  \n",
       "3225  0.0  0.000  0.0  0.000  0.000  0.0  5.888   29.0   53.0  \n",
       "3135  0.0  0.000  0.0  0.000  0.000  0.0  1.800    5.0    9.0  \n",
       "4124  0.0  0.219  0.0  0.000  0.000  0.0  1.225    5.0   49.0  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e336dbdc",
   "metadata": {},
   "source": [
    "# Decision Tree Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4515a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_impurity(labels, criteria = 'entropy'):\n",
    "    '''\n",
    "        Gets the impurity of a given node\n",
    "        Input Parameters\n",
    "        ----------\n",
    "        labels : list\n",
    "            holds the list of class labels\n",
    "        criteria : string\n",
    "            possible values : 'entropy', 'gini'\n",
    "            default value : 'entropy'\n",
    "        Returns\n",
    "        --------------\n",
    "        impurity : float\n",
    "            impurity of a given node either as per entropy or gini impurity criteria\n",
    "        '''\n",
    "    _,count_labels = np.unique(labels, return_counts=True) # get the counts of elements belonging to each class\n",
    "    prob_i = count_labels / len(labels) # probability of i-th class \n",
    "    if criteria == 'entropy':\n",
    "        return -np.sum(prob_i*np.log2(prob_i)) # Entropy\n",
    "    elif criteria == 'gini':\n",
    "        return 1-np.sum(prob_i*prob_i) # Gini impurity\n",
    "#counts = get_impurity([2,2,4,4,4]) # testing on sample values\n",
    "#print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3ccba5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(child_nodes, parent_node, criteria = 'entropy'):\n",
    "        '''\n",
    "        Gets the impurity reduction when a parent node is divided into child nodes\n",
    "        Input Parameters\n",
    "        ----------\n",
    "        child_nodes : list\n",
    "            holds child node element as lists inside another list\n",
    "        parent_node : list\n",
    "            holds the parent elements as a list\n",
    "        criteria : string\n",
    "            possible values : 'entropy', 'gini'\n",
    "            default value : 'entropy'\n",
    "        Returns\n",
    "        --------------\n",
    "        info_gain : float\n",
    "            information gain ( reduction in impurity) resulting from the split \n",
    "        '''\n",
    "        parent_impurity = get_impurity(parent_node, criteria)# get entropy/gini impurity , based on parameter \"criteria\"\n",
    "        child_impurity_list = [get_impurity(child,criteria) for child in child_nodes]\n",
    "        child_counts = [len(child) for child in child_nodes] # get the number of elments in each child node\n",
    "        # get a weighted average of child impurities, weighted by child node sizes\n",
    "        weighted_avg_child_impurity = np.sum([child_impurity_list[i]*child_counts[i] for i in range(len(child_nodes))])/len(parent_node)\n",
    "        # get the difference with parent node impurity\n",
    "        info_gain = parent_impurity - weighted_avg_child_impurity ## get the impurity difference\n",
    "        return info_gain\n",
    "#testing on sample values    \n",
    "#information_gain([[1,1,1],[2,1,2,2]],[1,1,1,2,1,2,2],'gini')#example of values    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf53b6a5",
   "metadata": {},
   "source": [
    "#testing the function -- information_gain\n",
    "information_gain([np.array([1,1,1]),np.array([2,1,2,2])],np.array([1,1,1,2,1,2,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19907fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tree(dataset, feature, threshold):\n",
    "    '''\n",
    "    Splits the 'dataset' dataframe into two parts based on the chosen threshold & returns them\n",
    "    \n",
    "    '''\n",
    "    condition_check_success_records = dataset[dataset[feature].astype(float)>=threshold]## satisfies the condition\n",
    "    condition_check_failure_records = dataset[dataset[feature].astype(float)<threshold]## fails the condition\n",
    "    return condition_check_success_records, condition_check_failure_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "366fbf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_best_threshold(dataset, feature,criteria ,threshold):\n",
    "    '''for a given feature , find the  best threshold in a Node\n",
    "    Parameters\n",
    "    -------------\n",
    "    dataset - dataframe\n",
    "        The set of records at a given node we need to split further\n",
    "    feature - str\n",
    "        the feature / column/attribute we are checking currently\n",
    "    threshold -\n",
    "        the current threshold. We iterate through all the values in of a feature in the function check_all_features() and\n",
    "        pass them one by one to this function\n",
    "    Returns \n",
    "    -------------\n",
    "    info_gain : float\n",
    "        the info gain resulting from the current splitting condition ( threshold, feature)\n",
    "    threshold : threshold \n",
    "        corresponding [info_gain, threshold] are passed a list to check_all_features()\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    left_tree, right_tree = split_tree(dataset, feature, float(threshold))# success , failure branches\n",
    "    if left_tree.shape[1] == 0 or right_tree.shape[1] == 0:# If Row number of any branch=0, skip\n",
    "                return 0, none\n",
    "    info_gain = information_gain([left_tree.iloc[ :, -1].values, right_tree.iloc[ :, -1].values], dataset.iloc[ :, -1].values, criteria)\n",
    "    return [info_gain, threshold]\n",
    "    \n",
    "                \n",
    "def check_all_features(dataset,criteria, feature):\n",
    "    '''for a given node, check all features to find best splitting condition\n",
    "    Returns\n",
    "    ------------\n",
    "    returns [highest_info_gain, feature, best_threshold] where best_threshold is the best threshold to split a given node\n",
    "    for a given features\n",
    "    '''\n",
    "    all_values = list( set(dataset[feature].astype(float)))\n",
    "    highest_info_gain, optimal_feature, best_threshold =0 ,None, None\n",
    "    info_gain_list = list(map(functools.partial(get_best_threshold, dataset, feature, criteria),all_values))\n",
    "    highest_info_gain, best_threshold = max(info_gain_list, key=lambda element: element[0])\n",
    "    return [highest_info_gain, feature, best_threshold]\n",
    "                \n",
    "def best_split_conditions(dataset, criteria):\n",
    "    '''for a given node , find the best splitting condition ( i.e. which feature to split, at what threshold & \n",
    "    what is the resulting information gain)'''\n",
    "    highest_info_gain = 0  \n",
    "    num_features = dataset.shape[1] # number of attributes\n",
    "    optimal_feature, best_threshold =None, None\n",
    "    col_list  = dataset.columns[:len(dataset.columns)-1].tolist()# get all the input feature list.\n",
    "    info_gain_list = list(map(functools.partial(check_all_features, dataset, criteria), col_list))\n",
    "    highest_info_gain, optimal_feature, best_threshold =  max(info_gain_list, key=lambda element: element[0])\n",
    "    #print(highest_info_gain, optimal_feature, best_threshold)\n",
    "    return highest_info_gain, optimal_feature, best_threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1283ab7a",
   "metadata": {},
   "source": [
    "## Tree Node Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55f645e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Non_Terminal_DT_Node:\n",
    "    \"\"\"\n",
    "    A class that represents a Non Terminal Node (Decision Node) in a Decision Tree i.e. a node that is subsequently split into other nodes\n",
    "    ...\n",
    "    Attributes\n",
    "    ----------\n",
    "    true_child_tree : object of the class DecisionTree\n",
    "        holds the the sub tree / child tree / branch which has elements that satisfy the splitting condition\n",
    "    false_child_tree : object of the class DecisionTree\n",
    "        holds the sub tree / child tree / branch which has elements that fails the splitting condition\n",
    "    optimal_feature : str, best_threshold: float\n",
    "        together these two attributes give us the best splitting condition at any node\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, true_child_tree, false_child_tree, optimal_feature, best_threshold):\n",
    "       \n",
    "        self.true_child_tree = true_child_tree\n",
    "        self.false_child_tree = false_child_tree\n",
    "        self.optimal_feature = optimal_feature\n",
    "        self.best_threshold = best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b6e83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Terminal_Node:\n",
    "    \"\"\"\n",
    "    A class that represents a Terminal Node (Leaf Node) in a Decision Tree i.e. a node that is NOT subsequently split into other nodes\n",
    "    ...\n",
    "    Attributes\n",
    "    ----------\n",
    "    predicted_classlabel : str\n",
    "    The Majority class label in a given Leaf Node\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset):\n",
    "        self.predicted_classlabel = dataset.iloc[:,-1].value_counts().idxmax()#to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9dd3b66",
   "metadata": {},
   "source": [
    "# FUNCTIONS used for  BUILDING the TREE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae6447db",
   "metadata": {},
   "outputs": [],
   "source": [
    " def build_decision_tree(training_set, ig_threshold, criteria, minimum_leaf =5):#\n",
    "        '''\n",
    "        builds the decision tree by learning the optimum splitting condition\n",
    "        Input Parameters\n",
    "        ----------\n",
    "        training_set : dataframe\n",
    "            Holds the records in the current node.\n",
    "        ig_threshold : float\n",
    "            If info gain is less than this threshold, stop splitting & ignore the current split\n",
    "        criteria : string\n",
    "            possible values : 'entropy', 'gini'\n",
    "            default value : 'entropy'\n",
    "        Returns\n",
    "        --------------\n",
    "        Non_Terminal_DT_Node : object of class Non_Terminal_DT_Node\n",
    "            holds the Decision Nodes i.e. the nodes that are split further\n",
    "        Terminal_Node : object of class Terminal_Node\n",
    "            holds the terminal /Leaf nodes\n",
    "        \n",
    "        '''\n",
    "        #minimum_leaf = 5 #\n",
    "        if len(training_set.iloc[:,-1].unique().tolist()) ==1: # IF a node has just one class, declare it as Terminal /Leaf\n",
    "            return Terminal_Node(training_set)\n",
    "        elif len(training_set.iloc[:,-1].unique().tolist()) > 1:\n",
    "            if training_set.shape[0]<=minimum_leaf:  # minimum leaf count based pre pruning\n",
    "                return Terminal_Node(training_set)\n",
    "            info_gain, optimal_feature, best_threshold = best_split_conditions(training_set, criteria)\n",
    "            if info_gain <= ig_threshold :      #impuriity based pruning\n",
    "                return Terminal_Node(training_set)\n",
    "            true_child_set, false_child_set = split_tree(training_set, optimal_feature, best_threshold)\n",
    "            true_child_tree = build_decision_tree(true_child_set, ig_threshold, criteria) # recursively build the true child tree\n",
    "            false_child_tree = build_decision_tree(false_child_set, ig_threshold, criteria)\n",
    "            #print(' optimal_feature : '+str(optimal_feature)+' best_threshold : '+str(best_threshold))\n",
    "            return Non_Terminal_DT_Node(true_child_tree, false_child_tree, optimal_feature, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e300d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_test_instance(test_instance, tree_node):\n",
    "        '''\n",
    "        classifies a new test instance based on a previously learnt/built decision tree\n",
    "        Input Parameters\n",
    "        ----------\n",
    "        test_instance : nd-array\n",
    "            Holds the current test instance\n",
    "        tree_node : object of class DecisionTree\n",
    "        Returns\n",
    "        --------------\n",
    "        predicted_classlabel : str\n",
    "            the predicted label for the test instance\n",
    "            '''\n",
    "        \n",
    "        result = 0 #\n",
    "        \n",
    "        if isinstance(tree_node, Terminal_Node):\n",
    "            #print('node.label_prediction_dict :'+str(node.label_prediction_dict))\n",
    "            return tree_node.predicted_classlabel # if it is leaf node, return the class label\n",
    "        \n",
    "        test_instance = pd.Series(test_instance)\n",
    "        if float(test_instance[tree_node.optimal_feature])>=tree_node.best_threshold:\n",
    "            return classify_test_instance(test_instance, tree_node.true_child_tree )\n",
    "        else:\n",
    "            return classify_test_instance(test_instance, tree_node.false_child_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d29d475",
   "metadata": {},
   "source": [
    "# DECISION TREE CLASS IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ad36d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    \"\"\"\n",
    "    A class that represents a Decision Tree\n",
    "    ...\n",
    "    Attributes\n",
    "    ----------\n",
    "    ig_threshold : float\n",
    "        a information gain threshold that tells when to stop splitting the nodes\n",
    "    criteria : str\n",
    "        the criteria to measure impurity. Two options entropy(default) and gini impurity\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    learn (training_set)\n",
    "        Learns / builds the decision tree as per the criteria & information gain minimum threshold\n",
    "    classify (training_set)\n",
    "        Given a test data, predicts the label based on the existing tree\n",
    "    \"\"\"\n",
    "    def __init__(self,ig_threshold, criteria, minimum_leaf =5):\n",
    "        self.ig_threshold = ig_threshold\n",
    "        self.criteria = criteria\n",
    "        self.minimum_leaf =minimum_leaf \n",
    "        tree = {}\n",
    "    \n",
    "    def learn(self, training_set):\n",
    "        # implement this function\n",
    "        self.tree = build_decision_tree(training_set,self.ig_threshold ,self.criteria, self.minimum_leaf)\n",
    "        \n",
    "    # implement this function\n",
    "\n",
    "    def classify(self, test_instance):\n",
    "        return classify_test_instance(test_instance, self.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5623fe5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sample in module pandas.core.generic:\n",
      "\n",
      "sample(self: 'FrameOrSeries', n=None, frac=None, replace=False, weights=None, random_state=None, axis=None) -> 'FrameOrSeries'\n",
      "    Return a random sample of items from an axis of object.\n",
      "    \n",
      "    You can use `random_state` for reproducibility.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    n : int, optional\n",
      "        Number of items from axis to return. Cannot be used with `frac`.\n",
      "        Default = 1 if `frac` = None.\n",
      "    frac : float, optional\n",
      "        Fraction of axis items to return. Cannot be used with `n`.\n",
      "    replace : bool, default False\n",
      "        Allow or disallow sampling of the same row more than once.\n",
      "    weights : str or ndarray-like, optional\n",
      "        Default 'None' results in equal probability weighting.\n",
      "        If passed a Series, will align with target object on index. Index\n",
      "        values in weights not found in sampled object will be ignored and\n",
      "        index values in sampled object not in weights will be assigned\n",
      "        weights of zero.\n",
      "        If called on a DataFrame, will accept the name of a column\n",
      "        when axis = 0.\n",
      "        Unless weights are a Series, weights must be same length as axis\n",
      "        being sampled.\n",
      "        If weights do not sum to 1, they will be normalized to sum to 1.\n",
      "        Missing values in the weights column will be treated as zero.\n",
      "        Infinite values not allowed.\n",
      "    random_state : int, array-like, BitGenerator, np.random.RandomState, optional\n",
      "        If int, array-like, or BitGenerator (NumPy>=1.17), seed for\n",
      "        random number generator\n",
      "        If np.random.RandomState, use as numpy RandomState object.\n",
      "    \n",
      "        .. versionchanged:: 1.1.0\n",
      "    \n",
      "            array-like and BitGenerator (for NumPy>=1.17) object now passed to\n",
      "            np.random.RandomState() as seed\n",
      "    \n",
      "    axis : {0 or â€˜indexâ€™, 1 or â€˜columnsâ€™, None}, default None\n",
      "        Axis to sample. Accepts axis number or name. Default is stat axis\n",
      "        for given data type (0 for Series and DataFrames).\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series or DataFrame\n",
      "        A new object of same type as caller containing `n` items randomly\n",
      "        sampled from the caller object.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrameGroupBy.sample: Generates random samples from each group of a\n",
      "        DataFrame object.\n",
      "    SeriesGroupBy.sample: Generates random samples from each group of a\n",
      "        Series object.\n",
      "    numpy.random.choice: Generates a random sample from a given 1-D numpy\n",
      "        array.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    If `frac` > 1, `replacement` should be set to `True`.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame({'num_legs': [2, 4, 8, 0],\n",
      "    ...                    'num_wings': [2, 0, 0, 0],\n",
      "    ...                    'num_specimen_seen': [10, 2, 1, 8]},\n",
      "    ...                   index=['falcon', 'dog', 'spider', 'fish'])\n",
      "    >>> df\n",
      "            num_legs  num_wings  num_specimen_seen\n",
      "    falcon         2          2                 10\n",
      "    dog            4          0                  2\n",
      "    spider         8          0                  1\n",
      "    fish           0          0                  8\n",
      "    \n",
      "    Extract 3 random elements from the ``Series`` ``df['num_legs']``:\n",
      "    Note that we use `random_state` to ensure the reproducibility of\n",
      "    the examples.\n",
      "    \n",
      "    >>> df['num_legs'].sample(n=3, random_state=1)\n",
      "    fish      0\n",
      "    spider    8\n",
      "    falcon    2\n",
      "    Name: num_legs, dtype: int64\n",
      "    \n",
      "    A random 50% sample of the ``DataFrame`` with replacement:\n",
      "    \n",
      "    >>> df.sample(frac=0.5, replace=True, random_state=1)\n",
      "          num_legs  num_wings  num_specimen_seen\n",
      "    dog          4          0                  2\n",
      "    fish         0          0                  8\n",
      "    \n",
      "    An upsample sample of the ``DataFrame`` with replacement:\n",
      "    Note that `replace` parameter has to be `True` for `frac` parameter > 1.\n",
      "    \n",
      "    >>> df.sample(frac=2, replace=True, random_state=1)\n",
      "            num_legs  num_wings  num_specimen_seen\n",
      "    dog            4          0                  2\n",
      "    fish           0          0                  8\n",
      "    falcon         2          2                 10\n",
      "    falcon         2          2                 10\n",
      "    fish           0          0                  8\n",
      "    dog            4          0                  2\n",
      "    fish           0          0                  8\n",
      "    dog            4          0                  2\n",
      "    \n",
      "    Using a DataFrame column as weights. Rows with larger value in the\n",
      "    `num_specimen_seen` column are more likely to be sampled.\n",
      "    \n",
      "    >>> df.sample(n=2, weights='num_specimen_seen', random_state=1)\n",
      "            num_legs  num_wings  num_specimen_seen\n",
      "    falcon         2          2                 10\n",
      "    fish           0          0                  8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b6c816",
   "metadata": {},
   "source": [
    "# RANDOM FOREST CLASS IMPLEMENTATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2aca9380",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Forest_Custom:\n",
    "    '''\n",
    "    A Class that represents a Random Forest.\n",
    "    Attributes :\n",
    "    --------------------------------------------------------------------\n",
    "    total_DT_to_build - how many total trees to build\n",
    "    list_of_trees - list of trained Decision Trees\n",
    "    --------------------------------------------\n",
    "    Methods:\n",
    "    ---------------------------------------------\n",
    "    fit_rf_custom - \n",
    "    Fits total_DT_to_build number of DTs\n",
    "    Randomly selects m features/columns without replacement.\n",
    "    Then randomly selects frac fraction of rows/records with Replacement\n",
    "    \n",
    "    rf_predict_custom_v2 - \n",
    "    Predicts on the Test data using all the Decision Tree- majority votes\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, total_DT_to_build=5):\n",
    "        self.total_DT_to_build = total_DT_to_build\n",
    "        # To enlist each decision tree in a list after fitting it on train data\n",
    "        self.list_of_trees = []\n",
    "    def fit_rf_custom(self, X,y,m,frac =0.8,seed=0):\n",
    "        '''\n",
    "        fits total_DT_to_build Number of Decision Trees to the various Bootstrapped Samples. This method does not return\n",
    "        OOB accuracy . For OOB, please Random_Forest_Custom_OOB() Class implemented at the bottom portion of the Notebook\n",
    "        Input Parameters\n",
    "        -----\n",
    "        X- Features/ Indepedent Variables\n",
    "        y - Target / Dependent Variables\n",
    "        m - how many features to select for fitting each Decision Tree\n",
    "        frac - how many fraction of records to select from the Train dataset with replacement\n",
    "        seed - random state\n",
    "        \n",
    "        '''\n",
    "\n",
    "        self.list_of_trees = []\n",
    "        count_of_DTree_built_so_far = 0\n",
    "        \n",
    "        while count_of_DTree_built_so_far < self.total_DT_to_build:\n",
    "                #print(count_of_DTree_built_so_far,self.total_DT_to_build )\n",
    "                tree = DecisionTree(0.005,'gini')\n",
    "                X2 = X.sample(n=m,axis='columns',random_state=seed)# selecting m features randomly\n",
    "                training_set = X2.copy()\n",
    "                \n",
    "                training_set[57] = y\n",
    "                training_set = training_set.sample(frac = frac,axis='rows',random_state=seed,replace=True)\n",
    "                # selecting frac fraction of rows , with replacement \n",
    "                tree.learn( training_set )\n",
    "                self.list_of_trees.append(tree)\n",
    "                count_of_DTree_built_so_far += 1\n",
    "                print('{} Decision Tree built'.format(count_of_DTree_built_so_far))\n",
    "\n",
    "    def rf_predict_custom_v2(self, X_test):\n",
    "        prediction_list,results = [],[]\n",
    "        prediction_list = np.array([X_test.apply(lambda x: tree.classify(x), axis=1) for tree in self.list_of_trees]).mean(axis =0)\n",
    "        return prediction_list.astype(np.int16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b8ac6ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf2111c",
   "metadata": {},
   "source": [
    "# COMMENTED THE BELOW CODES AS I AM CHECKING A LOT OF HYPERPARAMETER COMBINATIONS - HENCE TAKES TIME TO RUN,\n",
    "# FOR THE OUTPUT OF THESE CELLS PLEASE CHECK THE OTHER NOTEBOOK \"Q5_ML_Assignment_RF_CS21MDS14025_DETAILED_NOTEBOOK.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3ecd85",
   "metadata": {},
   "source": [
    "# CHECK HOW THE RF PERFORMANCE VARIES WRT. M parameter"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7f6bea59",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 8 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2313c752",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 10 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ff373067",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 12 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef22cbcd",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 14 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "57506ea0",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 7 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8e43c26e",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 6 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "648119f7",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 15 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3fa23b38",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 16 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ead764a6",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 17 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "31b10ac8",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 18 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "39fc7e94",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 19 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5c6fed8d",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 19 ,frac=0.8, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "91ba5cb3",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 19 ,frac=0.9, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cda844a",
   "metadata": {},
   "source": [
    "# BEST MODEL SELECTED - REST ARE COMMENTED IN THIS NOTEBOOK \n",
    "# THIS GIVES 3rd BEST ACCURACY- \n",
    "# BUT RUNS in reasonable time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea557eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Decision Tree built\n",
      "2 Decision Tree built\n",
      "3 Decision Tree built\n",
      "4 Decision Tree built\n",
      "5 Decision Tree built\n",
      "6 Decision Tree built\n",
      "7 Decision Tree built\n",
      "8 Decision Tree built\n",
      "9 Decision Tree built\n",
      "10 Decision Tree built\n",
      "11 Decision Tree built\n",
      "12 Decision Tree built\n",
      "0.8921071687183201\n",
      "time taken in minutes :  13.913658344745636\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 25 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.perf_counter()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b26cdf4",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "raw",
   "id": "597f1297",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 30 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "433e1b96",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 35 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8b473688",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "model = Random_Forest_Custom(total_DT_to_build =12)\n",
    "\n",
    "model.fit_rf_custom(X_train,y_train, m = 40 ,frac=1, seed =10)\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "print(accuracy_score(y_test, spam_predicted))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str((end - start)/60))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90ab1543",
   "metadata": {},
   "source": [
    "for m in range(7, 17):\n",
    "    start = time.time()\n",
    "    gc.collect()\n",
    "    model = Random_Forest_Custom()\n",
    "    model.fit_rf_custom(X_train,y_train, m = 14 ,frac=1, seed =10)\n",
    "\n",
    "    spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "    print('no of features :',m, ' and accuracy obtained is : ',accuracy_score(y_test, spam_predicted))\n",
    "    end = time.time()\n",
    "    print('time taken in minutes : ', str((end - start)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc58df47",
   "metadata": {},
   "source": [
    "s = np.array(spam_predicted)\n",
    "print(X_test.shape)\n",
    "accuracy_score(y_test, s)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f7d6b0a9",
   "metadata": {},
   "source": [
    "start = time.time()\n",
    "spam_predicted = model.rf_predict_custom(X_test)\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str(end - start))\n",
    "start = time.time()\n",
    "spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str(end - start))\n",
    "# time taken in minutes :   0.6357081850369771 for 2 DT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ef20b",
   "metadata": {},
   "source": [
    "# Comparison with sklearn algo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "699b8122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL:  0.945691527878349\n",
      "time taken in minutes :  0.2420041561126709\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "rf = RandomForestClassifier(n_estimators = 12, max_features = 25) \n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_sklearn = rf.predict(X_test)\n",
    "print(\"ACCURACY OF THE MODEL: \", accuracy_score(y_test, y_pred_sklearn))\n",
    "end = time.time()\n",
    "print('time taken in minutes : ', str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b161ab",
   "metadata": {},
   "source": [
    "# QUESTION 5.b #HOW THE RF PERFORMANCE VARIES WRT. M parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3bbcfb2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACCURACY OF THE MODEL with  6  no. of features is  0.945691527878349\n",
      "ACCURACY OF THE MODEL with  7  no. of features is  0.9514844315713251\n",
      "ACCURACY OF THE MODEL with  8  no. of features is  0.9543808834178131\n",
      "ACCURACY OF THE MODEL with  9  no. of features is  0.9471397538015931\n",
      "ACCURACY OF THE MODEL with  10  no. of features is  0.9507603186097031\n",
      "ACCURACY OF THE MODEL with  11  no. of features is  0.9500362056480811\n",
      "ACCURACY OF THE MODEL with  12  no. of features is  0.9536567704561911\n",
      "ACCURACY OF THE MODEL with  13  no. of features is  0.9478638667632151\n",
      "ACCURACY OF THE MODEL with  14  no. of features is  0.9514844315713251\n",
      "ACCURACY OF THE MODEL with  15  no. of features is  0.9543808834178131\n",
      "ACCURACY OF THE MODEL with  16  no. of features is  0.9529326574945691\n",
      "ACCURACY OF THE MODEL with  17  no. of features is  0.9485879797248371\n",
      "ACCURACY OF THE MODEL with  18  no. of features is  0.944243301955105\n",
      "ACCURACY OF THE MODEL with  19  no. of features is  0.944243301955105\n",
      "ACCURACY OF THE MODEL with  20  no. of features is  0.944967414916727\n",
      "ACCURACY OF THE MODEL with  21  no. of features is  0.9500362056480811\n",
      "ACCURACY OF THE MODEL with  22  no. of features is  0.9493120926864591\n",
      "ACCURACY OF THE MODEL with  23  no. of features is  0.9493120926864591\n",
      "ACCURACY OF THE MODEL with  24  no. of features is  0.9543808834178131\n",
      "ACCURACY OF THE MODEL with  25  no. of features is  0.945691527878349\n",
      "ACCURACY OF THE MODEL with  26  no. of features is  0.9493120926864591\n",
      "ACCURACY OF THE MODEL with  27  no. of features is  0.9514844315713251\n",
      "ACCURACY OF THE MODEL with  28  no. of features is  0.942070963070239\n",
      "ACCURACY OF THE MODEL with  29  no. of features is  0.9485879797248371\n",
      "ACCURACY OF THE MODEL with  30  no. of features is  0.939174511223751\n",
      "ACCURACY OF THE MODEL with  31  no. of features is  0.944243301955105\n",
      "ACCURACY OF THE MODEL with  32  no. of features is  0.944967414916727\n",
      "ACCURACY OF THE MODEL with  33  no. of features is  0.9471397538015931\n",
      "ACCURACY OF THE MODEL with  34  no. of features is  0.944243301955105\n",
      "ACCURACY OF THE MODEL with  35  no. of features is  0.944243301955105\n",
      "ACCURACY OF THE MODEL with  36  no. of features is  0.9362780593772628\n",
      "ACCURACY OF THE MODEL with  37  no. of features is  0.9471397538015931\n",
      "ACCURACY OF THE MODEL with  38  no. of features is  0.939174511223751\n",
      "ACCURACY OF THE MODEL with  39  no. of features is  0.9471397538015931\n",
      "time taken in minutes :  10.971775399986655\n"
     ]
    }
   ],
   "source": [
    "start = time.perf_counter()\n",
    "for m in range(6,40,1):\n",
    "    rf = RandomForestClassifier(n_estimators = 12, max_features = m) \n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred_sklearn = rf.predict(X_test)\n",
    "    print(\"ACCURACY OF THE MODEL with \",m, \" no. of features is \", accuracy_score(y_test, y_pred_sklearn))\n",
    "    end = time.perf_counter()\n",
    "print('time taken in minutes : ', str(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84a2adc",
   "metadata": {},
   "source": [
    "# QUESTION 5.c  OUT OF BAG ERROR "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e7c47e",
   "metadata": {},
   "source": [
    "# Out of Bag Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58c77573",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Forest_Custom_OOB:\n",
    "    '''\n",
    "    A Class that represents a Random Forest that also calculates Out of Bag Error .\n",
    "    Attributes :\n",
    "    --------------------------------------------------------------------\n",
    "    total_DT_to_build - how many total trees to build\n",
    "    list_of_trees - list of trained Decision Trees\n",
    "    --------------------------------------------\n",
    "    Methods:\n",
    "    ---------------------------------------------\n",
    "    fit_rf_custom - \n",
    "    Fits total_DT_to_build number of DTs\n",
    "    Randomly selects m features/columns without replacement.\n",
    "    Then randomly selects frac fraction of rows/records with Replacement.\n",
    "    the Rows NOT selected are considered Out of Bag Samples for each DT.\n",
    "    \n",
    "    For each Decision Tree, we check the accuracy for the Out of Bag (OOB) Samples & also print their average Accuracy\n",
    "    \n",
    "\n",
    "    \n",
    "    rf_predict_custom_v2 - \n",
    "    Predicts on the Test data using all the Decision Tree- majority votes\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, total_DT_to_build=5):\n",
    "        self.total_DT_to_build = total_DT_to_build\n",
    "        # To enlist each decision tree in a list after fitting it on train data\n",
    "        self.list_of_trees = []\n",
    "    def fit_rf_custom(self, X,y,m,frac =0.8,seed=0):\n",
    "        '''\n",
    "        fits total_DT_to_build Number of Decision Trees to the various Bootstrapped Samples. \n",
    "        Also returns Out of Bag Accuracy .\n",
    "        Input Parameters\n",
    "        -----\n",
    "        X- Features/ Indepedent Variables\n",
    "        y - Target / Dependent Variables\n",
    "        m - how many features to select for fitting each Decision Tree\n",
    "        frac - how many fraction of records to select from the Train dataset with replacement\n",
    "        seed - random state\n",
    "        \n",
    "        '''\n",
    "\n",
    "        self.list_of_trees = []\n",
    "        count_of_DTree_built_so_far = 0\n",
    "        OOB_accuracy_scores, OOB_errors = [],[]\n",
    "        while count_of_DTree_built_so_far < self.total_DT_to_build:\n",
    "                #print(count_of_DTree_built_so_far,self.total_DT_to_build )\n",
    "                tree = DecisionTree(0.005,'gini')\n",
    "                X2 = X.sample(n=m,axis='columns',random_state=seed)\n",
    "                training_set = X2.copy()\n",
    "                \n",
    "                training_set[57] = y\n",
    "                X2[57] = y\n",
    "                #select frac fraction of rows/records with Replacement i.e. some rows might be repeated\n",
    "                training_set = training_set.sample(frac = frac,axis='rows',random_state=seed,replace=True)\n",
    "                training_index = training_set.index\n",
    "                tree.learn( training_set )# fit the decision tree on the bootstrap sample\n",
    "                \n",
    "                remaining_indices = np.setdiff1d(X2.index.values, training_set.index.values)\n",
    "                ## Create a OOB sample set with the records that were NOT part of bootstrap training sample\n",
    "                OOB_samples = X2.loc[remaining_indices,:] \n",
    "                # predict & check the accuracy on the OOB samples for each Decision Tree\n",
    "                \n",
    "                OOB_pred = OOB_samples.apply(lambda x: tree.classify(x), axis=1)\n",
    "                OOB_accuracy = accuracy_score(OOB_pred,OOB_samples.iloc[:,-1] )\n",
    "                OOB_accuracy_scores.append(OOB_accuracy)\n",
    "                OOB_errors.append(1- OOB_accuracy)\n",
    "                self.list_of_trees.append(tree)\n",
    "                count_of_DTree_built_so_far += 1\n",
    "                #print('{} Decision Tree built'.format(count_of_DTree_built_so_far))\n",
    "        print('Bootstrap sample size',training_set.shape,'OOB sample size ',OOB_samples.shape)\n",
    "        print('the OOB accuracy scores are ', OOB_accuracy_scores, ' the AVG being : ', np.array(OOB_accuracy_scores).mean())\n",
    "        print('the OOB errors are ', OOB_errors, ' the AVG being : ', np.array(OOB_errors).mean())\n",
    "        return OOB_errors\n",
    "\n",
    "\n",
    "    def rf_predict_custom_v2(self, X_test):\n",
    "        prediction_list,results = [],[]\n",
    "        prediction_list = np.array([X_test.apply(lambda x: tree.classify(x), axis=1) for tree in self.list_of_trees]).mean(axis =0)\n",
    "        return prediction_list.astype(np.int16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de8ad88",
   "metadata": {},
   "source": [
    "# FOR A SET OF VALUES OF m "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e6eae26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap sample size (2898, 7) OOB sample size  (1316, 7)\n",
      "the OOB accuracy scores are  [0.7249240121580547, 0.7249240121580547, 0.7249240121580547, 0.7249240121580547, 0.7249240121580547, 0.7249240121580547, 0.7249240121580547, 0.7249240121580547, 0.7249240121580547, 0.7249240121580547, 0.7249240121580547, 0.7249240121580547]  the AVG being :  0.7249240121580547\n",
      "the OOB errors are  [0.2750759878419453, 0.2750759878419453, 0.2750759878419453, 0.2750759878419453, 0.2750759878419453, 0.2750759878419453, 0.2750759878419453, 0.2750759878419453, 0.2750759878419453, 0.2750759878419453, 0.2750759878419453, 0.2750759878419453]  the AVG being :  0.2750759878419453\n",
      "test set accuracy for m =  6 is :  0.7168718320057929\n",
      "Bootstrap sample size (2898, 9) OOB sample size  (1316, 9)\n",
      "the OOB accuracy scores are  [0.756838905775076, 0.756838905775076, 0.756838905775076, 0.756838905775076, 0.756838905775076, 0.756838905775076, 0.756838905775076, 0.756838905775076, 0.756838905775076, 0.756838905775076, 0.756838905775076, 0.756838905775076]  the AVG being :  0.7568389057750761\n",
      "the OOB errors are  [0.24316109422492405, 0.24316109422492405, 0.24316109422492405, 0.24316109422492405, 0.24316109422492405, 0.24316109422492405, 0.24316109422492405, 0.24316109422492405, 0.24316109422492405, 0.24316109422492405, 0.24316109422492405, 0.24316109422492405]  the AVG being :  0.24316109422492405\n",
      "test set accuracy for m =  8 is :  0.7465604634322954\n",
      "Bootstrap sample size (2898, 13) OOB sample size  (1316, 13)\n",
      "the OOB accuracy scores are  [0.8062310030395137, 0.8062310030395137, 0.8062310030395137, 0.8062310030395137, 0.8062310030395137, 0.8062310030395137, 0.8062310030395137, 0.8062310030395137, 0.8062310030395137, 0.8062310030395137, 0.8062310030395137, 0.8062310030395137]  the AVG being :  0.8062310030395138\n",
      "the OOB errors are  [0.19376899696048633, 0.19376899696048633, 0.19376899696048633, 0.19376899696048633, 0.19376899696048633, 0.19376899696048633, 0.19376899696048633, 0.19376899696048633, 0.19376899696048633, 0.19376899696048633, 0.19376899696048633, 0.19376899696048633]  the AVG being :  0.19376899696048633\n",
      "test set accuracy for m =  12 is :  0.8015930485155685\n",
      "Bootstrap sample size (2898, 17) OOB sample size  (1316, 17)\n",
      "the OOB accuracy scores are  [0.851823708206687, 0.851823708206687, 0.851823708206687, 0.851823708206687, 0.851823708206687, 0.851823708206687, 0.851823708206687, 0.851823708206687, 0.851823708206687, 0.851823708206687, 0.851823708206687, 0.851823708206687]  the AVG being :  0.8518237082066871\n",
      "the OOB errors are  [0.14817629179331304, 0.14817629179331304, 0.14817629179331304, 0.14817629179331304, 0.14817629179331304, 0.14817629179331304, 0.14817629179331304, 0.14817629179331304, 0.14817629179331304, 0.14817629179331304, 0.14817629179331304, 0.14817629179331304]  the AVG being :  0.14817629179331301\n",
      "test set accuracy for m =  16 is :  0.8435916002896452\n",
      "Bootstrap sample size (2898, 21) OOB sample size  (1316, 21)\n",
      "the OOB accuracy scores are  [0.8844984802431611, 0.8844984802431611, 0.8844984802431611, 0.8844984802431611, 0.8844984802431611, 0.8844984802431611, 0.8844984802431611, 0.8844984802431611, 0.8844984802431611, 0.8844984802431611, 0.8844984802431611, 0.8844984802431611]  the AVG being :  0.8844984802431611\n",
      "the OOB errors are  [0.11550151975683887, 0.11550151975683887, 0.11550151975683887, 0.11550151975683887, 0.11550151975683887, 0.11550151975683887, 0.11550151975683887, 0.11550151975683887, 0.11550151975683887, 0.11550151975683887, 0.11550151975683887, 0.11550151975683887]  the AVG being :  0.11550151975683891\n",
      "test set accuracy for m =  20 is :  0.8573497465604635\n"
     ]
    }
   ],
   "source": [
    "model = Random_Forest_Custom_OOB(total_DT_to_build =12)\n",
    "avg_OOB_errors, test_errors =[],[]\n",
    "for m in [6, 8, 12, 16, 20]:\n",
    "\n",
    "    OOB_errors = model.fit_rf_custom(X_train,y_train, m = m ,frac=.9, seed =10)#19\n",
    "    avg_OOB_errors.append(np.array(OOB_errors).mean())\n",
    "    spam_predicted = model.rf_predict_custom_v2(X_test)\n",
    "    print('test set accuracy for m = ',m, 'is : ', accuracy_score(y_test, spam_predicted))\n",
    "    test_errors.append(1- accuracy_score(y_test, spam_predicted))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b13e5ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.plot([6, 8, 12, 16, 20], avg_OOB_errors)\n",
    "plt.plot([6, 8, 12, 16, 20], test_errors)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c2ff1f57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>m</th>\n",
       "      <th>avg_OOB_errors</th>\n",
       "      <th>test_errors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.275076</td>\n",
       "      <td>0.283128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>0.243161</td>\n",
       "      <td>0.253440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>0.193769</td>\n",
       "      <td>0.198407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0.148176</td>\n",
       "      <td>0.156408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>0.115502</td>\n",
       "      <td>0.142650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    m  avg_OOB_errors  test_errors\n",
       "0   6        0.275076     0.283128\n",
       "1   8        0.243161     0.253440\n",
       "2  12        0.193769     0.198407\n",
       "3  16        0.148176     0.156408\n",
       "4  20        0.115502     0.142650"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OOB_Vs_test_df = pd.DataFrame ({\"m\": [6, 8, 12, 16, 20], \"avg_OOB_errors\": avg_OOB_errors,\"test_errors\": test_errors})\n",
    "OOB_Vs_test_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
